# Awesome-LLM-Computational-Argumentation
The Hub of Computational Argumentation in the Era of LLM, where you can find surveys, papers, datasets, benchmarks, and evaluations of commonly used LLMs on computational Argumentation tasks.
## Table of Contents

- [Awesome-LLM-Computational-Argumentation](#awesome-llm-computational-argumentation)
  - [Table of Contents](#table-of-contents)
  - [Evaluation](#evaluation)
  - [Benchmark \& datasets](#benchmark--datasets)
  - [Survey](#survey)
  - [Papers](#papers)
    - [Argument Mining](#argument-mining)
    - [Argument Generation](#argument-generation)
    - [Quality Assessment](#quality-assessment)
    - [Debate For LLM inference](#debate-for-llm-inference)
  - [Contributing](#contributing)



## Evaluation

## Benchmark & datasets

|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2022-03       | [IAM: A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks](https://arxiv.org/abs/2203.12257)                                                                                                                      |   ACL<br> ![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F17e37e8ea24a6c19d10f65d4554696d6d7cd4f4f%3Ffields%3DcitationCount&query=%24.citationCount&label=citation)  |



## Survey
|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2023-11       | [Exploring the Potential of Large Language Models in Computational Argumentation](https://arxiv.org/abs/2311.09022)                                                                                                                      |   ACL<br> ![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F20f3abdd3640718d8f268aaea8b2ac3b8978d2af%3Ffields%3DcitationCount&query=%24.citationCount&label=citation)  |


## Papers


### Argument Mining
|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2024-04       | [Can Language Models Recognize Convincing Arguments?](https://arxiv.org/abs/2404.00750)                                                                                                                      |   Arxiv<br> ![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fedf260dee56a06d897547fb460a1e317d7eb571b%3Ffields%3DcitationCount&query=%24.citationCount&label=citation)  |

### Argument Generation
|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2024-06       | [Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking](https://arxiv.org/abs/2406.13905)                                                                                                                      |   Arxiv<br> ![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F156f1a58661814f60ab4abaf027f64e47d1c4fdf%3Ffields%3DcitationCount&query=%24.citationCount&label=citation)  |


### Quality Assessment
|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2024-04       | [Are Large Language Models Reliable Argument Quality Annotators?](https://arxiv.org/abs/2404.09696)                                                                                                                      |   Arxiv<br> ![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F75ac87c7e9bdd81ec69ff03ef26336ac2c34ed86%3Ffields%3DcitationCount&query=%24.citationCount&label=citation)  |


### Debate For LLM inference

|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2024-05       |[DEBATE: Devil's Advocate-Based Assessment and Text Evaluation](https://arxiv.org/abs/2405.09935)|Arxiv<br> ![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F87da4349c42fef4d1f4926a68c09a486661e9c2d%3Ffields%3DcitationCount&query=%24.citationCount&label=citation)
| 2024-02       | [Debating with More Persuasive LLMs Leads to More Truthful Answers](https://arxiv.org/abs/2402.06782)                                                                                                                      |   Arxiv<br> ![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe5d297461c53153b9b7aae099c146741e97322b8%3Ffields%3DcitationCount&query=%24.citationCount&label=citation)  |






## Contributing