# Awesome-LLM-Computational-Argumentation
The Hub of Computational Argumentation in the Era of LLM, where you can find surveys, papers, datasets, benchmarks, and evaluations of commonly used LLMs on computational Argumentation tasks.
## Table of Contents

- [Awesome-LLM-Computational-Argumentation](#awesome-llm-computational-argumentation)
  - [Table of Contents](#table-of-contents)
  - [Evaluation](#evaluation)
  - [Benchmark \& datasets](#benchmark--datasets)
  - [Survey](#survey)
  - [Papers](#papers)
    - [Argument Mining](#argument-mining)
    - [Argument Generation](#argument-generation)
    - [Quality Assessment](#quality-assessment)
    - [Debate For LLM inference](#debate-for-llm-inference)
  - [Contributing](#contributing)



## Evaluation


![image.png](https://kashiwa-pic.oss-cn-beijing.aliyuncs.com/20240815202830.png)

## Benchmark & datasets

|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
|2024-06|[Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks](https://arxiv.org/abs/2406.15130)|EPIA 2023
|2024-06|[Which Side Are You On? A Multi-task Dataset for End-to-End Argument Summarisation and Evaluation](https://arxiv.org/abs/2406.03151)|ACL 2024
|2024-06|[OpenDebateEvidence: A Massive-Scale Argument Mining and Summarization Dataset](https://arxiv.org/abs/2406.14657)|ACL 2024
| 2022-03       | [IAM: A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks](https://arxiv.org/abs/2203.12257)|ACL




## Survey
|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2023-11       | [Exploring the Potential of Large Language Models in Computational Argumentation](https://arxiv.org/abs/2311.09022)                                                                                                                      |   ACL<br> 


## Papers


### Argument Mining
|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
|2024-07|[Argument Mining in Data Scarce Settings: Cross-lingual Transfer and Few-shot Techniques](https://arxiv.org/abs/2407.03748)|ACL 2024
|2024-06|[In-Context Learning and Fine-Tuning GPT for Argument Mining](https://arxiv.org/abs/2406.06699)|Arxiv
|2024-05|[WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining](https://arxiv.org/abs/2405.00828)|ASONAM
|2024-05|[DMON: A Simple yet Effective Approach for Argument Structure Learning](https://arxiv.org/abs/2405.01216)|	COLING 2024
|2024-04|[Exploring Key Point Analysis with Pairwise Generation and Graph Partitioning](https://arxiv.org/abs/2404.11384)|NAACL 2024
|2024-04|[A School Student Essay Corpus for Analyzing Interactions of Argumentative Structure and Quality](https://arxiv.org/abs/2404.02529)|NAACL 2024
|2024-04|[TACO -- Twitter Arguments from COnversations](https://arxiv.org/abs/2404.00406)|Arxiv
|2024-02|[Can Large Language Models perform Relation-based Argument Mining?](https://arxiv.org/abs/2402.11243)|ACL 2024
|2024-01|[End-to-End Argument Mining over Varying Rhetorical Structures](https://arxiv.org/abs/2401.11218)|Arxiv
|2023-12|[Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs in Language Pretraining](https://arxiv.org/abs/2312.00874)|EMNLP 2023
|2023-10|[Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining](https://arxiv.org/abs/2310.12172)|EMNLP
|2023-10|[TILFA: A Unified Framework for Text, Image, and Layout Fusion in Argument Mining](https://arxiv.org/abs/2310.05210)|EMNLP 2023
|2023-05|[AQE: Argument Quadruplet Extraction via a Quad-Tagging Augmented Generative Approach](https://arxiv.org/abs/2305.19902)|ACL 2023
|2023-02|[VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining](https://arxiv.org/abs/2302.12584)|EMNLP 2023 
|2022-09|[Perturbations and Subpopulations for Testing Robustness in Token-Based Argument Unit Recognition](https://arxiv.org/abs/2209.14780)|COLING 2022
|2022-09   |[ImageArg: A Multi-modal Tweet Dataset for Image Persuasiveness Mining](https://arxiv.org/abs/2209.06416)|COLING

### Argument Generation
|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2024-06       | [Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking](https://arxiv.org/abs/2406.13905)                                                                                                                      |   Arxiv<br> 
|2023-12|[Argue with Me Tersely: Towards Sentence-Level Counter-Argument Generation](https://arxiv.org/abs/2312.13608)|EMNLP 2023
|2023-10|[From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models](https://arxiv.org/abs/2310.17857)|	EMNLP 2023
|2023-09|[Claim Optimization in Computational Argumentation](https://arxiv.org/abs/2212.08913)| INLG 2023
|2023-07|[DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge Graphs](https://arxiv.org/abs/2307.04090)|EMNLP 2023
|2023-01|[Conclusion-based Counter-Argument Generation](https://arxiv.org/abs/2301.09911)|eacl-23
|2022-10|[MOCHA: A Multi-Task Training Approach for Coherent Text Generation from Cognitive Perspective](https://arxiv.org/abs/2210.14650)|EMNLP 2022
|2022-05 |[RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText Generators](https://arxiv.org/abs/2205.12590) |NAACL 2022
|


### Quality Assessment
|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
|2024-06|[Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks](https://arxiv.org/abs/2406.15130)|EPIA 2023
| 2024-04       | [Can Language Models Recognize Convincing Arguments?](https://arxiv.org/abs/2404.00750)                                                                                                                      |   Arxiv
|2024-03|[Argument Quality Assessment in the Age of Instruction-Following Large Language Models](https://arxiv.org/abs/2403.16084)|COLING 2024
|2023-11|[Automatic Analysis of Substantiation in Scientific Peer Reviews](https://arxiv.org/abs/2311.11967)|EMNLP 2023 
|2023-05|[Contextualizing Argument Quality Assessment with Relevant Knowledge](https://arxiv.org/abs/2305.12280)|NAACL 2024	
|2023-01|[Conclusion-based Counter-Argument Generation](https://arxiv.org/abs/2301.09911)|eacl-23
|2022-12|[Claim Optimization in Computational Argumentation](https://arxiv.org/abs/2212.08913)| INLG 2023


### Debate For LLM inference

|  Date    | Paper                                                                                                                                                                               | Publication |
| :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
|2024-08|[Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate](https://arxiv.org/abs/2408.04472)|Arxiv
| 2024-05       |[DEBATE: Devil's Advocate-Based Assessment and Text Evaluation](https://arxiv.org/abs/2405.09935)|Arxiv
| 2024-02       | [Debating with More Persuasive LLMs Leads to More Truthful Answers](https://arxiv.org/abs/2402.06782) |   ICML 2024
|2023-12|[Recourse under Model Multiplicity via Argumentative Ensembling (Technical Report)](https://arxiv.org/abs/2312.15097)|AAMAS 2024
|2023-10|[From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models](https://arxiv.org/abs/2310.17857)|	EMNLP 2023
|2023-10|[Let Models Speak Ciphers: Multiagent Debate through Embeddings](https://arxiv.org/abs/2310.06272)|ICLR 2024
|2023-08|[ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate](https://arxiv.org/abs/2308.07201)|Arixv






## Contributing